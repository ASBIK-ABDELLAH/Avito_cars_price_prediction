{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  Introduction\n\nAfter scraping an e-commerce website in my last project, https://github.com/ASBIK-ABDELLAH/Avito_scraping, i've decided to make this data useful by cleaning it and by trying to build a machine learning model which predict the price of cars.\n\nThis project will contain my pre-processing of data and machine learning models.\n\n## **The Dataset**\n\nThe dataset is a CSV file, which contains the following columns:\n \n 'car_city' : The name of city where is the car sold.\\\n 'car_cv_man_auto': Horsepower of the car and being automatic or manual.\\\n 'car_equipements': Car equipements.\\\n 'car_information ': Some information about the car.\\\n 'car_name': The car name.\\\n 'car_price': The car price."},{"metadata":{},"cell_type":"markdown","source":"# 1. **Importing necessary module for Cleaning**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/av-cars/items_av_cars_1.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I will create a bunch of functions based on my analysis of data, which will clean my CSV file.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Droping columns that don't contain the full information about if the car is manuel or automatic.\ndef drop_cv_manuelle(df,column):\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(\n        lambda x: np.nan if (str(x)[-1] ==\"-\") or (str(x)[0] ==\"-\") or (\"CV\" not in str(x)) else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_price(df,column):\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: str(x)[:len(x)-3]) ## delete ,DH\n    def space(x):\n        while str(x).find(\" \") != -1 :\n            x = str(x)[:str(x).find(\" \")] + str(x)[str(x).find(\" \")+1:]                 ### delete space between numbers.\n        return x\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(\n        lambda x: space(x) )\n\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].astype(float)\n    df.where(df[\"{}\".format(column)] > 10000, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_city(df,column):\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: str(x)[:str(x).find(\",\")]) ## find \",\" and choose city","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_car_cv_man_auto(df,column):\n    df[\"fuel\"] = df[\"{}\".format(column)].apply(lambda x: str(x)[:str(x).find(\",\")])\n    df[\"CV\"] = df[\"{}\".format(column)].apply(lambda x: str(x)[str(x).find(\",\")+1:str(x).rfind(\",\")])\n    df[\"CV\"] = df[\"CV\"].apply(lambda x: str(x)[0] if \"P\" not in str(x) else \"41\")\n    df[\"man_auto\"] = df[\"{}\".format(column)].apply(lambda x: str(x)[str(x).rfind(\",\")+1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_car_information(df,column):\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: str(x)[16:])\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].str.split(\",\")\n    \n    def alphabet_up(x):\n        for i in string.ascii_uppercase:\n            x = x [1:] if i in x[0] else x\n        return x\n    def alphabet_low(x):\n        for i in string.ascii_lowercase:\n            x = x [1:] if i in x[0] else x\n        return x\n    \n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: alphabet_up(x))\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: alphabet_low(x))\n  \n    df[\"Kilometrage\"] = df[\"{}\".format(column)].apply(lambda x: x[0] if '-' in x[0] else(x[1] if ('-' in x[1]) and ('0' or '9') in x[1] else np.nan))\n    df.dropna(subset=[\"Kilometrage\"], axis='index', how='any', inplace=True)\n    \n    \n\n    df[\"First_selling\"] = df[\"{}\".format(column)].apply(lambda x: True if \"Oui\" in str(x) else False)\n    \n    df[\"Year_of_Model\"] = df[\"{}\".format(column)].apply(lambda x: x[1] if '-'and ' ' not in x[1] else(x[0] if ('-' and ' ' not in x[0]) else \"1980\"))\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: x[2:-1] if \"Oui\" or \"Non\" in x[-1] else x[2:])\n    \n    \n    df[\"Origin_car\"] = df[\"{}\".format(column)].apply(\n        lambda x: x[-1] if ('WW au Maroc'== x[-1] or 'Dédouanée'== x[-1] or 'Importée neuve'== x[-1] or 'Pas encore dédouanée'== x[-1])  else np.nan)\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(\n        lambda x: x[:-1] if ('WW au Maroc'== x[-1] or 'Dédouanée'== x[-1] or 'Importée neuve'== x[-1] or 'Pas encore dédouanée'== x[-1]) else x)\n    \n    \n    \n    df[\"Mark\"] = df[\"{}\".format(column)].apply(lambda x: x[0])\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: x[1:] if len(x) >1 else np.nan)\n\n   \n    df[\"Model\"] = df[\"{}\".format(column)].apply(lambda x: x[0] if type(x) is list else np.nan)\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: x[1:] if type(x) is list else x)\n    \n    \n    df[\"Nbr_doors\"] = df[\"{}\".format(column)].apply(lambda x: x[0] if type(x) is list and len(x) != 0 else np.nan )\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### convert equipements to binary\ndef clean_car_equipements(df,column):\n    df[\"Jantes_aluminium\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Jantes aluminium\" not in str(x) else True)\n    df[\"Airbags\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Airbags\" not in str(x) else True)\n    df[\"Climatisation\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Climatisation\" not in str(x) else True)\n    df[\"navigation_Systeme\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Système de navigation\" not in str(x) else True)\n    df[\"GPS\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"GPS\" not in str(x) else True)\n    df[\"Sièges_cuir\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Sièges cuir\" not in str(x) else True)\n    df[\"Radar_back\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Radar de recul\" not in str(x) else True)\n    df[\"Back_camera\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Caméra de recul\" not in str(x) else True)\n    df[\"Electric_windows\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Vitres électriques\" not in str(x) else True)\n    df[\"ABS\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"ABS\" not in str(x) else True)\n    df[\"ESP\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"ESP\" not in str(x) else True)\n    df[\"Speed_regulator\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Régulateur de vitesse\" not in str(x) else True)\n    df[\"Vitess_limitor\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Limiteur de vitesse\" not in str(x) else True)\n    df[\"CD\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"CD\" not in str(x) else True)\n    df[\"MP3\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"MP3\" not in str(x) else True)\n    df[\"Bluetooth\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Bluetooth\" not in str(x) else True)\n    df[\"Board_computer\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Ordinateur de bord\" not in str(x) else True)\n    df[\"Remote_central_locking\"] = df[\"{}\".format(column)].apply(\n        lambda x: False if \"Verrouillage centralisé à distance\" not in str(x) else True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Some values in Kilometrage columns contained words isntead of number, so i replace them by a nan value.\ndef clean_Kilometrage(df,column):\n    def space(x):\n        while str(x).find(\" \") != -1 :\n            x = str(x)[:str(x).find(\" \")] + str(x)[str(x).find(\" \")+1:]\n        return x\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(\n        lambda x: space(x))\n    \n    def alphabet_up(x):\n        for i in string.ascii_uppercase:\n            x = str(x) if i not in str(x) else np.nan\n        return x\n    def alphabet_low(x):\n        for i in string.ascii_lowercase:\n            x = str(x) if i not in str(x) else np.nan\n        return x\n    \n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: alphabet_up(x))\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(lambda x: alphabet_low(x))\n    df.dropna(subset=[\"{}\".format(column)], axis='index', how='any', inplace=True)\n    df[\"{}\".format(column)] = df[\"{}\".format(column)].str.split(\"-\")\n    \n    df[\"{}\".format(column)] = df[\"{}\".format(column)].apply(\n         lambda x: (float(x[0]) + float(x[1]))/2 if len(x) !=1 else float(x[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\n\ndf = df.drop(['_type'], axis=1)\ndf = df.dropna(subset=['car_price', 'car_information'], axis='index', how='any')\n\ndrop_cv_manuelle(df, \"car_cv_man_auto\")\nclean_price(df, \"car_price\")\nclean_city(df, \"car_city\")\ndf = df.dropna(subset=['car_cv_man_auto'], axis='index', how='any')\nclean_car_cv_man_auto(df, \"car_cv_man_auto\")\ndf.drop(['car_cv_man_auto'], axis=1, inplace=True)\nclean_car_information(df, 'car_information')\ndf.drop(['car_information'], axis=1, inplace=True)\nclean_car_equipements(df, \"car_equipements\")\ndf.drop(['car_equipements'], axis=1, inplace=True)\nclean_Kilometrage(df,'Kilometrage')\ndf = df.where(df['car_price'] >= 10000.0)\ndf.drop(['car_name'], axis=1, inplace=True)\ndf.dropna(subset=['Nbr_doors'], axis='index', how='any', inplace=True)\n\ndf[\"Year_of_Model\"] = df[\"Year_of_Model\"].astype(int)\ndf[\"Nbr_doors\"] = df[\"Nbr_doors\"].astype(int)\ndf['CV'] = df['CV'].astype(int)\n\ndf.dropna(subset=['Mark'], axis='index', how='any', inplace=True)\ndf.dropna(subset=['Origin_car'], axis='index', how='any', inplace=True)\ndf = df[df[\"Mark\"] != \"Autres\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y0 = df['car_price'].values\ny0 = y0.reshape(-1, 1)\ny0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n'''for i in df.columns:\n    x1 = df['{}'.format(i)]\n    plt.scatter(x1, y0, color='blue')\n    plt.xlabel(i)\n    plt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### After visualisation, i made some intervals smaller because I've noticed that some data are misleading the learning of the algorithms.\ndf = df.where(df['car_price'] < 1.75 * 10**6)\ndf = df.dropna(subset=['car_price'], axis='index', how='any')\ndf = df.where(df['CV'] > 4)\ndf = df.where(df['CV'] < 40)\ndf = df.dropna(subset=['CV'], axis='index', how='any')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####Convert qualitative values to binary using dummies in the following columns.#### \ndummies_man_auto = pd.get_dummies(df.man_auto)\ndummies_fuel = pd.get_dummies(df.fuel)\ndummies_Origin_car = pd.get_dummies(df.Origin_car)\ndummies_Mark = pd.get_dummies(df.Mark)\ndummies_Model = pd.get_dummies(df.Model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df,dummies_man_auto,dummies_fuel,dummies_Origin_car,dummies_Mark,dummies_Model], axis=1)  #\ndf.drop(['man_auto','car_city','fuel','Origin_car','Mark','Model'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lancer'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['car_price'], axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import scale\nX_scaled = scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['car_price'].values\ny = y.reshape(-1, 1)\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=123)\n#X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\n'''\nmodel = xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.07,\n                 max_depth=3,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.5,\n                 reg_lambda=0.45,\n                 subsample=0.6,\n                 seed=42)\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)\n'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import StandardScaler\n#from sklearn.decomposition import PCA\n#scaler = StandardScaler()\n#X_train1 = scaler.fit_transform(X_train1)\n#X_test1 = scaler.fit_transform(X_test1)\n\nmodel = xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.07,\n                 max_depth=3,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.5,\n                 reg_lambda=0.45,\n                 subsample=0.6,\n                 seed=42)\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred =model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_train, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(300, 300))\n#xgboost.plot_importance(model, ax=ax)\nxgboost.plot_importance(model, ax=ax)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''  from sklearn.model_selection import GridSearchCV\nreg = LinearRegression()\n\nparam_grid = {'copy_X': np.arange(0.01, 0.1)}\nlasso_cv = GridSearchCV(reg, param_grid, cv=5)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.best_score_'''\n#reg.get_params().keys()\n#reg.fit(X_train, y_train)\n#reg.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred = reg.predict(X_test)\n#rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n#print(\"Root Mean Squared Error: {}\".format(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.linear_model import Ridge\nridge = Ridge(alpha=0.01, normalize=True)\nalphas = np.array([5, 0.5, 0.05, 0.005, 0.0005, 1, 0.1, 0.01,0.001, 0.0001, 0 ])\nridge_cv = GridSearchCV(lasso, param_grid=dict(alpha=alphas), cv=5)\nridge_cv.fit(X_train, y_train)\n#ridge_pred = ridge.predict(X_test)\n#ridge.score(X_test, y_test)\nridge_cv.best_score_'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nlasso = Lasso()\nalphas = np.array([3, 2.5,1])\nlasso_cv = GridSearchCV(lasso, param_grid=dict(alpha=alphas), cv=5)\nlasso_cv.fit(X_train, y_train)\nprint(lasso_cv.best_score_)\nprint(\"Tuned ratio: {}\".format(lasso_cv.best_params_))\n#lasso.score(X_test, y_test)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''# Import necessary modules\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\n \n# Create the hyperparameter grid\nl1_space = np.linspace(0, 1, 30)\nparam_grid = {'l1_ratio': l1_space}\n\n# Instantiate the ElasticNet regressor: elastic_net\nelastic_net = ElasticNet()\n\n# Setup the GridSearchCV object: gm_cv\ngm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n\n# Fit it to the training data\ngm_cv.fit(X_train, y_train)\n# Predict on the test set and compute metrics\ny_pred = gm_cv.predict(X_test)\nr2 = gm_cv.score(X_test, y_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\nprint(\"Tuned ElasticNet R squared: {}\".format(r2))\nprint(\"Tuned ElasticNet MSE: {}\".format(mse))'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules\n#from scipy.stats import randint\n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.model_selection import RandomizedSearchCV\n\n# Setup the parameters and distributions to sample from: param_dist\n#param_dist = {\"max_depth\": [3, None],\n              #\"max_features\": randint(1, 9),\n              #\"min_samples_leaf\": randint(1, 9),\n              #\"criterion\": [\"gini\", \"entropy\"]}","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}